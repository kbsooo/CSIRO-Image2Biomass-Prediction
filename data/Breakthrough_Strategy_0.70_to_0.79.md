# ğŸš€ Breakthrough Strategy: 0.70 â†’ 0.79+

## ğŸ“Š í˜„ì¬ ìƒí™© ë¶„ì„

### í˜„ì¬ ì ìˆ˜
- **Your Best Public LB**: 0.70
- **1ìœ„ Public LB**: 0.79
- **Gap**: 0.09 (ìƒë‹¹íˆ í° ì°¨ì´)

### í˜„ì¬ ì½”ë“œ ë¶„ì„

| Version | íŠ¹ì§• | ë¬¸ì œì  |
|---------|------|--------|
| v20/v26 | DINOv2 Large + FiLM + Dual View | ê¸°ë³¸ ë² ì´ìŠ¤ë¼ì¸ |
| v22 | Frozen backbone + ì‘ì€ Head | ì œí•œëœ í•™ìŠµ |
| v25 | VegIdx Late Fusion | ì¶”ê°€ ì •ë³´ì§€ë§Œ íš¨ê³¼ ì œí•œì  |
| v27 | ë‹¨ìˆœ ì•™ìƒë¸” (Simple/Rank Average) | ìµœì í™”ë˜ì§€ ì•Šì€ ì•™ìƒë¸” |

### ğŸ”´ í•µì‹¬ ë¬¸ì œì  ë°œê²¬

#### 1. **CV ì „ëµ ì˜¤ë¥˜** âš ï¸ (ê°€ì¥ ì‹¬ê°) - âœ… í•´ê²°ë¨
```python
# âŒ ì´ì „ ì½”ë“œ (ì˜ëª»ëœ ë°©ë²•)
groups = df['image_id']  # image_idë¡œ ê·¸ë£¹í•‘

# âœ… cv1ì—ì„œ ìˆ˜ì •ë¨
groups = df['Sampling_Date']  # ë‚ ì§œë³„ ê·¸ë£¹í•‘!
```

**ë¬¸ì œ**: Discussionì—ì„œ 126 votesë¥¼ ë°›ì€ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ëŠ” **Sampling_Dateë¡œ ê·¸ë£¹í•‘**í•´ì•¼ í•œë‹¤ëŠ” ê²ƒ!
- ê°™ì€ ë‚ ì§œì— ì´¬ì˜ëœ ì´ë¯¸ì§€ë“¤ì€ ë¹„ìŠ·í•œ ì¡°ê±´ ê³µìœ 
- `image_id`ë¡œ ê·¸ë£¹í•‘í•˜ë©´ ê°™ì€ ë‚ ì§œì˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ê°€ train/valì— ë¶„ë¦¬ë¨
- **ì‹¬ê°í•œ data leakage â†’ overfitting**

#### 2. **ì´ë¯¸ì§€ í•´ìƒë„ ì œí•œ** - âœ… í•´ê²°ë¨
```python
# âŒ ì´ì „
img_size = (512, 512)

# âœ… cv1ì—ì„œ ìˆ˜ì •ë¨
img_size = (560, 560)  # 14ì™€ 16 ëª¨ë‘ì˜ ë°°ìˆ˜
```

#### 3. **TTA ë¯¸ì‚¬ìš©** - âœ… í•´ê²°ë¨
- cv1_infer.pyì—ì„œ 4-fold TTA (HFlip x VFlip) êµ¬í˜„ë¨

#### 4. **ì•™ìƒë¸” ìµœì í™” ë¶€ì¡±**
- ê°€ì¤‘ì¹˜ ìµœì í™” ì—†ìŒ
- ëª¨ë¸ ë‹¤ì–‘ì„± ë¶€ì¡± (ëª¨ë‘ ê°™ì€ backbone)

#### 5. **Loss Function**
```python
main_loss = F.mse_loss(pred, main_targets)  # ë‹¨ìˆœ MSE
```
- ëŒ€íšŒ í‰ê°€ ì§€í‘œ(Weighted RÂ²)ì™€ ë‹¤ë¥¸ loss ì‚¬ìš©
- Dry_Total_gê°€ 50% ê°€ì¤‘ì¹˜ì¸ë° ë™ì¼í•˜ê²Œ ì·¨ê¸‰

---

## ğŸ¯ Breakthrough ì „ëµ (ìš°ì„ ìˆœìœ„ ìˆœ)

### âœ… Priority 1: CV ì „ëµ ìˆ˜ì • (ì˜ˆìƒ +0.03~0.05) - ì™„ë£Œ!

**cv1_train.pyì—ì„œ êµ¬í˜„ë¨**

```python
def create_proper_folds(df, n_splits=5):
    """Sampling_Date ê¸°ë°˜ ì˜¬ë°”ë¥¸ CV split"""
    df = df.copy()
    df['date_group'] = pd.to_datetime(df['Sampling_Date']).dt.strftime('%Y-%m-%d')
    df['strat_key'] = df['State'] + '_' + df['Month'].astype(str)

    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)

    df['fold'] = -1
    for fold, (_, val_idx) in enumerate(sgkf.split(
        df,
        df['strat_key'],
        groups=df['date_group']  # âš ï¸ í•µì‹¬: dateë¡œ ê·¸ë£¹í•‘!
    )):
        df.loc[val_idx, 'fold'] = fold

    return df
```

### âœ… Priority 2: ë” í° í•´ìƒë„ + TTA (ì˜ˆìƒ +0.02~0.03) - ì™„ë£Œ!

**cv1ì—ì„œ êµ¬í˜„ë¨:**
- í•´ìƒë„: 560x560 (14ì™€ 16 ëª¨ë‘ì˜ ë°°ìˆ˜)
- TTA: 4-fold flip (HFlip x VFlip)

### ğŸ”¥ Priority 3: Optuna HPO (ì˜ˆìƒ +0.02~0.03) â­ NEW

**ì´ì œ CVê°€ ì •ì§í•´ì¡Œìœ¼ë‹ˆ HPOê°€ ì˜ë¯¸ìˆìŒ!**

```python
import optuna

def objective(trial):
    cfg = CFG()

    # â­ ì‘ì€ ê°’ë¶€í„° íƒìƒ‰! (DINOv2ê°€ ì´ë¯¸ ì¢‹ì€ feature ì¶”ì¶œ)
    cfg.hidden_dim = trial.suggest_categorical('hidden_dim', [64, 128, 256, 512])
    cfg.num_layers = trial.suggest_int('num_layers', 1, 3)  # 1ë¶€í„°!
    cfg.dropout = trial.suggest_float('dropout', 0.1, 0.5)  # ë†’ì€ dropoutë„

    # lr, weight_decay
    cfg.lr = trial.suggest_float('lr', 1e-5, 1e-4, log=True)
    cfg.weight_decay = trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True)

    # 1-2 foldë§Œ ë¹ ë¥´ê²Œ ê²€ì¦
    cv_score = train_and_evaluate(cfg, folds=[0, 1])

    return cv_score

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)
```

#### ì™œ ì‘ì€ Headê°€ ë” ì¢‹ì„ ìˆ˜ ìˆëŠ”ê°€?

| ìš”ì†Œ | ì„¤ëª… |
|------|------|
| DINOv2 Large | ì´ë¯¸ 1024 dimì˜ í’ë¶€í•œ feature ì¶”ì¶œ |
| ë°ì´í„° í¬ê¸° | 357ê°œ ì´ë¯¸ì§€ (ë§¤ìš° ì‘ìŒ!) |
| ê²°ë¡  | í° Head = overfitting, ì‘ì€ Head = ì¼ë°˜í™” â†‘ |

#### Optuna íƒìƒ‰ ë²”ìœ„ (ìˆ˜ì •ë¨)

| íŒŒë¼ë¯¸í„° | ì´ì „ ë²”ìœ„ | ìˆ˜ì •ëœ ë²”ìœ„ |
|----------|-----------|-------------|
| hidden_dim | 256, 512, 768 | **64, 128, 256, 512** |
| num_layers | 2, 3, 4 | **1, 2, 3** |
| dropout | 0.1~0.3 | **0.1~0.5** |

#### ì˜ˆìƒ ìµœì ê°’ (ê°€ì„¤)
```python
# 357ê°œ ì´ë¯¸ì§€ + DINOv2 Large ì¡°í•©
cfg.hidden_dim = 128  # ë˜ëŠ” 256
cfg.num_layers = 1    # ë˜ëŠ” 2
cfg.dropout = 0.3     # ë†’ì€ regularization
```

### ğŸ”¥ Priority 4: Weighted Loss (ì˜ˆìƒ +0.01~0.02)

```python
class WeightedR2Loss(nn.Module):
    """ëŒ€íšŒ í‰ê°€ ì§€í‘œì— ë§ì¶˜ Loss"""
    def __init__(self):
        super().__init__()
        # [Green, Dead, Clover, GDM, Total]
        self.weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5])

    def forward(self, pred, target):
        green, clover, dead = pred[:, 0:1], pred[:, 2:3], pred[:, 1:2]
        gdm_pred = green + clover
        total_pred = gdm_pred + dead

        full_pred = torch.cat([green, dead, clover, gdm_pred, total_pred], dim=1)

        # ê°€ì¤‘ MSE (Dry_Total_gì— 50% ê°€ì¤‘ì¹˜!)
        weights = self.weights.to(pred.device)
        mse = (full_pred - target) ** 2
        weighted_mse = (mse * weights).mean()

        return weighted_mse
```

### ğŸ”¥ Priority 5: Multi-Seed Ensemble (ì˜ˆìƒ +0.005~0.01)

```python
# ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ë‹¤ì–‘í•œ seed í•™ìŠµ
seeds = [42, 123, 456]

all_preds = []
for seed in seeds:
    seed_everything(seed)
    model = train_model(best_cfg)  # Optuna ìµœì  íŒŒë¼ë¯¸í„°
    all_preds.append(model.predict(test))

final_pred = np.mean(all_preds, axis=0)
```

### ğŸ”¥ Priority 6: ìµœì  ì•™ìƒë¸” ê°€ì¤‘ì¹˜ (ì˜ˆìƒ +0.01)

```python
from scipy.optimize import minimize

def optimize_ensemble_weights(oof_preds_list, oof_targets):
    """OOF ê¸°ë°˜ ìµœì  ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì°¾ê¸°"""
    n_models = len(oof_preds_list)

    def objective(weights):
        weights = np.abs(weights) / np.abs(weights).sum()
        ensemble_pred = sum(w * p for w, p in zip(weights, oof_preds_list))
        return -competition_metric(oof_targets, ensemble_pred)

    x0 = np.ones(n_models) / n_models
    result = minimize(objective, x0, method='Nelder-Mead')

    optimal_weights = np.abs(result.x)
    optimal_weights = optimal_weights / optimal_weights.sum()

    return optimal_weights
```

---

## ğŸ“… ì—…ë°ì´íŠ¸ëœ ì‹¤í–‰ ê³„íš

### Phase 1: ê¸°ì¤€ì  í™•ë¦½ (Day 1-2) â† í˜„ì¬ ì§„í–‰ì¤‘
```
1. âœ… CV ìˆ˜ì • (Sampling_Date ê·¸ë£¹í•‘) - ì™„ë£Œ
2. âœ… í•´ìƒë„ 560x560 + TTA êµ¬í˜„ - ì™„ë£Œ
3. â³ cv1 í•™ìŠµ ì™„ë£Œ í›„ ì œì¶œ
4. CV-LB gap í™•ì¸ (ëª©í‘œ: â‰¤0.02)
```

**í˜„ì¬ CV ê²°ê³¼ (ì§„í–‰ì¤‘):**
- Fold 0: 0.7139
- Fold 1: 0.6474
- Fold 2: 0.6352
- ì˜ˆìƒ í‰ê· : ~0.66-0.68

âš ï¸ **ì´ì „ë³´ë‹¤ CVê°€ ë‚®ì€ ì´ìœ **: CVê°€ ì •ì§í•´ì§! (ì´ì „ CVëŠ” data leakageë¡œ ê±°ì§“ë§)

### Phase 2: Optuna HPO (Day 3-4) â­ NEW
```
1. ì‘ì€ Headë¶€í„° íƒìƒ‰ (hidden_dim: 64~512, num_layers: 1~3)
2. 2-fold ë¹ ë¥¸ ê²€ì¦ìœ¼ë¡œ 50+ trials
3. ìµœì  íŒŒë¼ë¯¸í„° í™•ì •
```

**Optuna íŒ:**
```python
# ë¹ ë¥¸ íƒìƒ‰ì„ ìœ„í•´ Fold ì¶•ì†Œ
cv_score = train_and_evaluate(cfg, folds=[0, 1])

# Pruningìœ¼ë¡œ ì‹œê°„ ì ˆì•½
pruner = optuna.pruners.MedianPruner()
study = optuna.create_study(direction='maximize', pruner=pruner)
```

### Phase 3: ìµœì  íŒŒë¼ë¯¸í„°ë¡œ Full Training (Day 5-6)
```
1. Optuna best paramsë¡œ 5-fold ì „ì²´ í•™ìŠµ
2. Multi-seed ì•™ìƒë¸” (best params Ã— 3 seeds)
3. Weighted Loss ì‹¤í—˜
4. ì œì¶œ ë° LB í™•ì¸
```

### Phase 4: ì•™ìƒë¸” ìµœì í™” (Day 7-8)
```
1. OOF ê¸°ë°˜ ìµœì  ê°€ì¤‘ì¹˜ ì°¾ê¸°
2. ë‹¤ì–‘í•œ ëª¨ë¸ ì¡°í•© ì‹¤í—˜
3. Blending ë˜ëŠ” Stacking ì‹œë„
```

### Phase 5: ìµœì¢… ì œì¶œ (Day 9)
```
1. ìµœì  ì¡°í•© ì„ íƒ
2. ì•ˆì „í•œ ë°±ì—… ì œì¶œ
3. Final submission
```

---

## ğŸ“Š ì˜ˆìƒ ê°œì„  íš¨ê³¼ (ì—…ë°ì´íŠ¸ë¨)

| ì „ëµ | ì˜ˆìƒ í–¥ìƒ | ë‚œì´ë„ | ìƒíƒœ |
|------|----------|--------|------|
| CV ìˆ˜ì • (Sampling_Date) | +0.03~0.05 | ì‰¬ì›€ | âœ… ì™„ë£Œ |
| í•´ìƒë„ 560 + TTA | +0.02~0.03 | ì‰¬ì›€ | âœ… ì™„ë£Œ |
| **Optuna HPO** | +0.02~0.03 | ì¤‘ê°„ | ğŸ”œ ë‹¤ìŒ |
| Weighted Loss | +0.01~0.02 | ì¤‘ê°„ | ëŒ€ê¸° |
| Multi-seed | +0.005~0.01 | ì‰¬ì›€ | ëŒ€ê¸° |
| ì•™ìƒë¸” ìµœì í™” | +0.01 | ì¤‘ê°„ | ëŒ€ê¸° |

**ì´ ì˜ˆìƒ í–¥ìƒ: +0.07~0.12 â†’ 0.77~0.82 ê°€ëŠ¥!**

---

## ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸: ì‘ì€ Headê°€ ì¢‹ì€ ì´ìœ 

### DINOv2 Large íŠ¹ì„±
```
Backbone output: 1024 dim
â”œâ”€â”€ ì‚¬ì „í•™ìŠµìœ¼ë¡œ ì´ë¯¸ í’ë¶€í•œ representation
â”œâ”€â”€ HeadëŠ” "feature â†’ target ë§¤í•‘"ë§Œ í•˜ë©´ ë¨
â””â”€â”€ ë³µì¡í•œ Head = overfitting ìœ„í—˜ â†‘
```

### ë°ì´í„° í¬ê¸° ê³ ë ¤
```
Train images: 357ê°œ (ë§¤ìš° ì‘ìŒ!)
â”œâ”€â”€ í° Head = íŒŒë¼ë¯¸í„° ë§ìŒ = overfitting
â”œâ”€â”€ ì‘ì€ Head = íŒŒë¼ë¯¸í„° ì ìŒ = ì¼ë°˜í™” â†‘
â””â”€â”€ ì •ì§í•œ CVì—ì„œëŠ” ì‘ì€ ëª¨ë¸ì´ ìœ ë¦¬
```

### ì‹¤ì œ ì‚¬ë¡€
| Backbone | ë°ì´í„° í¬ê¸° | ìµœì  Head |
|----------|------------|-----------|
| DINOv2-Large | ì†Œê·œëª¨ (357) | MLP 1-2 layers, 64-256 dim |
| DINOv2-Large | ëŒ€ê·œëª¨ (10K+) | MLP 2-3 layers, 256-512 dim |

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **CV-LB Correlation í™•ì¸**
   - CV ìˆ˜ì • í›„ Local CVì™€ LBì˜ ìƒê´€ê´€ê³„ í™•ì¸
   - CV â‰ˆ 0.67ì´ë©´ LB â‰ˆ 0.65-0.68 ì˜ˆìƒ

2. **Overfitting ì£¼ì˜**
   - 357ê°œ ì´ë¯¸ì§€ë¡œ ì‘ì€ ë°ì´í„°ì…‹
   - ì‘ì€ Head + ë†’ì€ Dropoutì´ ì•ˆì „

3. **Private LB ëŒ€ë¹„**
   - Public 53% / Private 47% ë¶„í• 
   - ê³¼ë„í•œ LB probing í”¼í•˜ê¸°

4. **Optuna ì£¼ì˜ì‚¬í•­**
   - ë„ˆë¬´ ë§ì€ trialsëŠ” CV overfitting ê°€ëŠ¥
   - 50-100 trials ì •ë„ê°€ ì ë‹¹

---

*Updated: 2026-01-19*
*Target: 0.70 â†’ 0.79+*
*Key Updates: Optuna HPO ì¶”ê°€, ì‘ì€ Head íƒìƒ‰ ì „ëµ*
