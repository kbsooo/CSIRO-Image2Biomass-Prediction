{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19935305",
   "metadata": {},
   "source": [
    "# CV3 Inference: TTA + WA Postprocessing\n",
    "\n",
    "**ÌïµÏã¨ Î≥ÄÍ≤ΩÏÇ¨Ìï≠**:\n",
    "1. ‚≠ê Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ (ÌïôÏäµÍ≥º ÎèôÏùº)\n",
    "2. ‚≠ê WA Dead=0 ÌõÑÏ≤òÎ¶¨\n",
    "3. 4-fold TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf534d1a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import timm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882af1f1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc21ad2",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa99012",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    BACKBONE_WEIGHTS = Path(\"/kaggle/input/pretrained-weights-biomass/dinov3_large/dinov3_large/dinov3_vitl16_qkvb.pth\")\n",
    "    \n",
    "    # CV3 Î™®Îç∏ Í≤ΩÎ°ú\n",
    "    MODELS_DIR = Path(\"/kaggle/input/csiro-cv3-models\")\n",
    "    \n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb.lvd1689m\"\n",
    "    img_size = (560, 560)\n",
    "    \n",
    "    # Model (CV1/CV3ÏôÄ ÎèôÏùº)\n",
    "    hidden_dim = 256\n",
    "    num_layers = 2\n",
    "    dropout = 0.3\n",
    "    \n",
    "    # Inference\n",
    "    batch_size = 16\n",
    "    num_workers = 0\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # TTA\n",
    "    use_tta = True\n",
    "    n_tta = 4\n",
    "    \n",
    "    # CV3 Ï†ÑÏ≤òÎ¶¨\n",
    "    use_clean_image = True\n",
    "    bottom_crop_ratio = 0.90\n",
    "    \n",
    "    # WA ÌõÑÏ≤òÎ¶¨\n",
    "    use_wa_postprocess = True\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"use_clean_image: {cfg.use_clean_image}\")\n",
    "print(f\"use_wa_postprocess: {cfg.use_wa_postprocess}\")\n",
    "\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2237f3",
   "metadata": {},
   "source": [
    "## ‚≠ê Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b998344",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def clean_image(img_array, bottom_crop_ratio=0.90):\n",
    "    \"\"\"Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨: timestamp Ï†úÍ±∞ + bottom crop\"\"\"\n",
    "    img = img_array.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # 1. Bottom crop\n",
    "    new_h = int(h * bottom_crop_ratio)\n",
    "    img = img[0:new_h, :]\n",
    "    \n",
    "    # 2. Orange timestamp inpainting\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    lower_orange = np.array([5, 150, 150])\n",
    "    upper_orange = np.array([25, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_orange, upper_orange)\n",
    "    mask = cv2.dilate(mask, np.ones((3, 3), np.uint8), iterations=2)\n",
    "    \n",
    "    if np.sum(mask) > 100:\n",
    "        img = cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edbea0",
   "metadata": {},
   "source": [
    "## ‚≠ê WA Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984ef48",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def postprocess_wa(preds, test_df):\n",
    "    \"\"\"\n",
    "    WA State ÌõÑÏ≤òÎ¶¨: Dead = 0 Í∞ïÏ†ú\n",
    "    DiscussionÏóêÏÑú Î∞úÍ≤¨Îêú 100% Ìå®ÌÑ¥\n",
    "    \"\"\"\n",
    "    preds = preds.copy()\n",
    "    wa_count = 0\n",
    "    \n",
    "    for idx in range(len(test_df)):\n",
    "        row = test_df.iloc[idx]\n",
    "        \n",
    "        # State ÌôïÏù∏ (test.csvÏóê StateÍ∞Ä ÏóÜÏùÑ Ïàò ÏûàÏùå)\n",
    "        state = row.get('State', None)\n",
    "        \n",
    "        if state == 'WA':\n",
    "            wa_count += 1\n",
    "            \n",
    "            # Dry_Dead_g = 0 Í∞ïÏ†ú\n",
    "            preds[idx, 1] = 0.0  # Dead index\n",
    "            \n",
    "            # GDMÍ≥º Total Ïû¨Í≥ÑÏÇ∞\n",
    "            green = preds[idx, 0]\n",
    "            clover = preds[idx, 2]\n",
    "            preds[idx, 3] = green + clover         # GDM\n",
    "            preds[idx, 4] = green + clover         # Total (Dead=0)\n",
    "    \n",
    "    if wa_count > 0:\n",
    "        print(f\"‚úì WA samples processed: {wa_count} (Dead forced to 0)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No WA samples found (State column may not exist)\")\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988cfc78",
   "metadata": {},
   "source": [
    "## üìä Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53125c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TestDatasetCV3(Dataset):\n",
    "    def __init__(self, df, cfg, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(self.cfg.DATA_PATH / row['image_path']).convert('RGB')\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # CV3: Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨\n",
    "        if self.cfg.use_clean_image:\n",
    "            img_array = clean_image(img_array, self.cfg.bottom_crop_ratio)\n",
    "        \n",
    "        h, w = img_array.shape[:2]\n",
    "        mid = w // 2\n",
    "        \n",
    "        left_array = img_array[:, :mid, :]\n",
    "        right_array = img_array[:, mid:, :]\n",
    "        \n",
    "        left_img = Image.fromarray(left_array)\n",
    "        right_img = Image.fromarray(right_array)\n",
    "        \n",
    "        if self.transform:\n",
    "            left_img = self.transform(left_img)\n",
    "            right_img = self.transform(right_img)\n",
    "        \n",
    "        return left_img, right_img, row['sample_id_prefix']\n",
    "\n",
    "\n",
    "def get_test_transform(cfg):\n",
    "    return T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d98f0",
   "metadata": {},
   "source": [
    "## üß† Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2616867",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, context):\n",
    "        return torch.chunk(self.mlp(context), 2, dim=1)\n",
    "\n",
    "\n",
    "def make_head(in_dim, hidden_dim, num_layers, dropout):\n",
    "    if num_layers == 1:\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    else:\n",
    "        layers = []\n",
    "        current_dim = in_dim\n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.Linear(current_dim, hidden_dim))\n",
    "            if i < num_layers - 1:\n",
    "                layers.append(nn.LayerNorm(hidden_dim))\n",
    "                layers.append(nn.ReLU(inplace=True))\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            current_dim = hidden_dim\n",
    "        layers.append(nn.Linear(hidden_dim, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class CSIROModelCV3(nn.Module):\n",
    "    def __init__(self, cfg, backbone_weights_path=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if backbone_weights_path and Path(backbone_weights_path).exists():\n",
    "            self.backbone = timm.create_model(cfg.model_name, pretrained=False, \n",
    "                                               num_classes=0, global_pool='avg')\n",
    "            state = torch.load(backbone_weights_path, map_location='cpu', weights_only=True)\n",
    "            self.backbone.load_state_dict(state, strict=False)\n",
    "        else:\n",
    "            self.backbone = timm.create_model(cfg.model_name, pretrained=True, \n",
    "                                               num_classes=0, global_pool='avg')\n",
    "        \n",
    "        feat_dim = self.backbone.num_features\n",
    "        combined_dim = feat_dim * 2\n",
    "        \n",
    "        self.film = FiLM(feat_dim)\n",
    "        \n",
    "        self.head_green = make_head(combined_dim, cfg.hidden_dim, cfg.num_layers, cfg.dropout)\n",
    "        self.head_clover = make_head(combined_dim, cfg.hidden_dim, cfg.num_layers, cfg.dropout)\n",
    "        self.head_dead = make_head(combined_dim, cfg.hidden_dim, cfg.num_layers, cfg.dropout)\n",
    "        \n",
    "        self.head_height = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 256), nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2), nn.Linear(256, 1)\n",
    "        )\n",
    "        self.head_ndvi = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 256), nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2), nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "    \n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        \n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "        \n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "        \n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)\n",
    "        \n",
    "        green = self.softplus(self.head_green(combined))\n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined))\n",
    "        \n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600aa7d",
   "metadata": {},
   "source": [
    "## üîÆ Inference with TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d664fa4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_with_tta(model, left, right, device, n_tta=4):\n",
    "    \"\"\"4-fold TTA: HFlip x VFlip\"\"\"\n",
    "    preds = []\n",
    "    \n",
    "    for hflip in [False, True]:\n",
    "        for vflip in [False, True]:\n",
    "            l = torch.flip(left, [3]) if hflip else left\n",
    "            r = torch.flip(right, [3]) if hflip else right\n",
    "            l = torch.flip(l, [2]) if vflip else l\n",
    "            r = torch.flip(r, [2]) if vflip else r\n",
    "            \n",
    "            pred = model(l.to(device), r.to(device))\n",
    "            preds.append(pred.cpu())\n",
    "            \n",
    "            if len(preds) >= n_tta:\n",
    "                break\n",
    "        if len(preds) >= n_tta:\n",
    "            break\n",
    "    \n",
    "    return torch.stack(preds).mean(0)\n",
    "\n",
    "\n",
    "def predict_batch(model, loader, cfg):\n",
    "    model.eval()\n",
    "    device = cfg.device\n",
    "    all_outputs, all_ids = [], []\n",
    "    \n",
    "    for left, right, ids in tqdm(loader, desc=\"Predicting\"):\n",
    "        if cfg.use_tta:\n",
    "            outputs = predict_with_tta(model, left, right, device, cfg.n_tta)\n",
    "        else:\n",
    "            outputs = model(left.to(device), right.to(device)).cpu()\n",
    "        \n",
    "        all_outputs.append(outputs.numpy())\n",
    "        all_ids.extend(ids)\n",
    "    \n",
    "    return np.concatenate(all_outputs), all_ids\n",
    "\n",
    "\n",
    "def predict_ensemble(cfg, loader):\n",
    "    \"\"\"5-fold ÏïôÏÉÅÎ∏î\"\"\"\n",
    "    model_files = sorted(cfg.MODELS_DIR.glob(\"model_fold*.pth\"))\n",
    "    print(f\"\\nFound {len(model_files)} models\")\n",
    "    \n",
    "    all_fold_preds = []\n",
    "    final_ids = None\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        print(f\"\\nLoading {model_file.name}...\")\n",
    "        \n",
    "        model = CSIROModelCV3(cfg, cfg.BACKBONE_WEIGHTS).to(cfg.device)\n",
    "        model.load_state_dict(torch.load(model_file, map_location=cfg.device))\n",
    "        \n",
    "        preds, ids = predict_batch(model, loader, cfg)\n",
    "        all_fold_preds.append(preds)\n",
    "        \n",
    "        if final_ids is None:\n",
    "            final_ids = ids\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return np.mean(all_fold_preds, axis=0), final_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de75c17",
   "metadata": {},
   "source": [
    "## üìã Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb6c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "test_df['sample_id_prefix'] = test_df['sample_id'].str.split('__').str[0]\n",
    "test_wide = test_df.drop_duplicates(subset=['image_path']).reset_index(drop=True)\n",
    "print(f\"Test samples: {len(test_wide)}\")\n",
    "\n",
    "# State Ïª¨Îüº ÌôïÏù∏\n",
    "if 'State' in test_wide.columns:\n",
    "    print(f\"‚úì State column exists\")\n",
    "    print(f\"  WA samples: {len(test_wide[test_wide['State'] == 'WA'])}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è State column not found - WA postprocessing will be skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43472cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ CV3 Inference: Clean Image + TTA + WA Postprocessing\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "transform = get_test_transform(cfg)\n",
    "dataset = TestDatasetCV3(test_wide, cfg, transform)\n",
    "loader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=False,\n",
    "                   num_workers=cfg.num_workers, pin_memory=True)\n",
    "\n",
    "predictions, sample_ids = predict_ensemble(cfg, loader)\n",
    "print(f\"\\nPredictions: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba99812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WA ÌõÑÏ≤òÎ¶¨\n",
    "if cfg.use_wa_postprocess and 'State' in test_wide.columns:\n",
    "    predictions = postprocess_wa(predictions, test_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee37654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏòàÏ∏° ÌÜµÍ≥Ñ\n",
    "print(\"\\n=== Prediction Statistics ===\")\n",
    "print(f\"{'Target':<15} {'Mean':>10} {'Std':>10} {'Min':>10} {'Max':>10}\")\n",
    "for idx, target in enumerate(TARGET_ORDER):\n",
    "    vals = predictions[:, idx]\n",
    "    print(f\"{target:<15} {vals.mean():>10.2f} {vals.std():>10.2f} {vals.min():>10.2f} {vals.max():>10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b958db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission ÏÉùÏÑ±\n",
    "pred_df = pd.DataFrame(predictions, columns=TARGET_ORDER)\n",
    "pred_df['sample_id_prefix'] = sample_ids\n",
    "\n",
    "sub_df = pred_df.melt(\n",
    "    id_vars=['sample_id_prefix'],\n",
    "    value_vars=TARGET_ORDER,\n",
    "    var_name='target_name',\n",
    "    value_name='target'\n",
    ")\n",
    "sub_df['sample_id'] = sub_df['sample_id_prefix'] + '__' + sub_df['target_name']\n",
    "\n",
    "submission = sub_df[['sample_id', 'target']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "sample_sub = pd.read_csv(cfg.DATA_PATH / \"sample_submission.csv\")\n",
    "assert len(submission) == len(sample_sub), \"Format mismatch!\"\n",
    "\n",
    "print(f\"\\n‚úÖ submission.csv saved\")\n",
    "print(f\"   {len(submission)} rows\")\n",
    "print(f\"   Clean image: {cfg.use_clean_image}\")\n",
    "print(f\"   WA postprocess: {cfg.use_wa_postprocess}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
